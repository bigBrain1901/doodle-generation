{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["vLW2SPCPhEAm"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installing and importing packages\n"],"metadata":{"id":"TuqHOKSke9Yf"}},{"cell_type":"code","source":["!pip install -qU svgwrite ndjson torch"],"metadata":{"id":"q1_oGHhBgUPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","import ndjson\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import time\n","import json\n","import svgwrite\n","from IPython.display import SVG, display, clear_output\n","import math"],"metadata":{"id":"-9qaG5kqf3Le"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setting pre-train parameters and user-controlled knobs"],"metadata":{"id":"GKpou1MkfGwm"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","dataset_url = 'https://storage.googleapis.com/quickdraw_dataset/full/simplified/triangle.ndjson'\n","max_doodle_len = 5\n","max_stroke_len = 1\n","max_gen_len = 1\n","\n","batch_size = 50\n","lr = 0.001\n","num_epochs = 1000\n","d_model = 512\n","num_layers = 6\n","num_heads = 8\n","ff_dim = 2048\n","dropout = 0.1"],"metadata":{"id":"7mfLw_2MX20e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Util functions for data pre-processing"],"metadata":{"id":"looAqmJWeyQQ"}},{"cell_type":"code","source":["def load_data():\n","    response = requests.get(dataset_url)\n","    data = ndjson.loads(response.text)\n","    return data"],"metadata":{"id":"u0L-PH36fYF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_useful_doodles(data):\n","    useful_doodles = []\n","    for doodle in data:\n","        if doodle['recognized']:\n","            useful_doodles.append(doodle['drawing'])\n","    return useful_doodles"],"metadata":{"id":"3dxOxfhTfyR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def zip_strokes(data):\n","    new_data = []\n","    for doodle in data:\n","        new_data.append([[list(x) for x in zip(stroke[0], stroke[1])] for stroke in doodle])\n","    return new_data"],"metadata":{"id":"KmHB50hlgN_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad_all_doodles(data):\n","    global max_stroke_len\n","    for doodle in data:\n","        max_stroke_len = max(\n","            max_stroke_len,\n","            max([len(stroke) for stroke in doodle])\n","        )\n","\n","    new_data = []\n","    for doodle in data:\n","        new_doodle = []\n","        for stroke in doodle:\n","            new_stroke = np.pad(\n","                stroke,\n","                ((max_stroke_len - len(stroke), 0), (0, 0)),\n","                mode='constant',\n","                constant_values=0\n","            )\n","            new_doodle.append(new_stroke)\n","        new_data.append(np.array(new_doodle))\n","\n","    for index, doodle in enumerate(new_data):\n","        if max_doodle_len <= doodle.shape[0]:\n","            new_data[index] = doodle[doodle.shape[0] - max_doodle_len:]\n","        else:\n","            new_data[index] = np.pad(\n","                doodle,\n","                ((max_doodle_len - doodle.shape[0], 0), (max_stroke_len - doodle.shape[1], 0), (2 - doodle.shape[2], 0))\n","            )\n","\n","    return np.array(new_data)"],"metadata":{"id":"I0yY3ZN9g3U9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Util functions for visualizations"],"metadata":{"id":"b-0jLEL1e2yX"}},{"cell_type":"code","source":["def draw_strokes_real_time(strokes):\n","    strokes = np.flip(strokes, axis=1)\n","\n","    dwg = svgwrite.Drawing(size=(255, 255))\n","    dwg.add(dwg.rect(insert=(0, 0), size=('100%', '100%'), fill='white'))\n","    display(SVG(dwg.tostring()))\n","\n","    for stroke in strokes:\n","        polyline = dwg.polyline([(int(stroke[0][0]), int(stroke[0][1]))], stroke=\"black\", fill=\"none\", stroke_width=2)\n","        dwg.add(polyline)\n","\n","        points = [(int(stroke[i][0]), int(stroke[i][1])) for i in range(1, len(stroke))]\n","        for point in points:\n","            if point == (0, 0): continue\n","            #print(point)\n","            polyline.points.append(point)\n","            display(SVG(dwg.tostring()))\n","            time.sleep(0.03)\n","            clear_output(wait=True)"],"metadata":{"id":"n8wJSbo0gajk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import, process and test our dataset"],"metadata":{"id":"sFMnegGpgm3l"}},{"cell_type":"code","source":["dataset = load_data()"],"metadata":{"id":"SMJs3n-ff8Ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doodles = extract_useful_doodles(dataset)"],"metadata":{"id":"_roLWdUHbYcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doodles = zip_strokes(doodles)\n","\n","# Sanity check\n","assert np.allclose(\n","    np.array([list(x) for x in zip(dataset[0]['drawing'][0][0], dataset[0]['drawing'][0][1])]),\n","    doodles[0][0]\n",")"],"metadata":{"id":"gs-kd5Qfkp3D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doodles = pad_all_doodles(doodles)\n","\n","# Sanity check\n","assert type(doodles[0]) == type(np.array([[]]))\n","assert all([doodle.shape[2] == 2 for doodle in doodles])"],"metadata":{"id":"_wnQlPr6ktto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(doodles.shape)"],"metadata":{"id":"DAb-rJsjuFar","executionInfo":{"status":"ok","timestamp":1712618499695,"user_tz":420,"elapsed":66,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f328b7c1-2dcb-4803-91e2-0ac5f760f505"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["(120500, 5, 106, 2)"]},"metadata":{}}]},{"cell_type":"code","source":["for i in np.random.randint(0, len(doodles), size=10):\n","    draw_strokes_real_time(doodles[i])\n","    time.sleep(0.5)"],"metadata":{"id":"s7_Hh9LGglG0","executionInfo":{"status":"ok","timestamp":1712618509253,"user_tz":420,"elapsed":9614,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5ef5e73-555d-4b48-c689-a09dceb4af68"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"255\" version=\"1.1\" width=\"255\"><defs/><rect fill=\"white\" height=\"100%\" width=\"100%\" x=\"0\" y=\"0\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"17,195 59,113 110,39 124,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"16,194 2,210 0,218 17,222 43,233 64,238 183,248 218,255 223,253 197,211 148,114 129,48 127,25 133,3\" stroke=\"black\" stroke-width=\"2\"/></svg>"},"metadata":{}}]},{"cell_type":"markdown","source":["# Train test val split"],"metadata":{"id":"iRQLbxXRnsgL"}},{"cell_type":"code","source":["class DoodleDataset(Dataset):\n","    def __init__(self, doodles):\n","        self.doodles = doodles\n","\n","    def __len__(self):\n","        return len(self.doodles)\n","\n","    def __getitem__(self, idx):\n","        # Get a single doodle from the array\n","        doodle = self.doodles[idx]\n","        return doodle"],"metadata":{"id":"SgHgzfUBSKJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    src = [torch.tensor(doodle[:-1]) for doodle in batch]\n","    tgt = [torch.tensor(doodle[-1]) for doodle in batch]\n","\n","    return torch.stack(src), torch.stack(tgt)"],"metadata":{"id":"VjHuQxyPxw3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","doodles = torch.tensor(doodles)\n","train_data, test_data = train_test_split(doodles, test_size=0.3, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n","\n","print(\"train data:\", len(train_data))\n","print(\"val data:\", len(val_data))\n","print(\"test data:\", len(test_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVRGdNxynvwA","executionInfo":{"status":"ok","timestamp":1712619019122,"user_tz":420,"elapsed":5235,"user":{"displayName":"Aditya Ashvin","userId":"05257660200781046204"}},"outputId":"f71d82ab-dbf1-4e9f-f0bf-9ad1248927cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-67-387fdd8c28f8>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  doodles = torch.tensor(doodles)\n"]},{"output_type":"stream","name":"stdout","text":["train data: 67500\n","val data: 16876\n","test data: 36162\n"]}]},{"cell_type":"code","source":["trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","valloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"],"metadata":{"id":"-KaY-yeATLXS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the transformer-based encoder"],"metadata":{"id":"ERVdcL0ygznu"}},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        batch_size, seq_len = x.size(0), x.size(2)\n","        pe = self.pe[:seq_len, :]\n","        x = pe\n","        return self.dropout(x)"],"metadata":{"id":"m3ngECtTq5RQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, ff_dim, dropout):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(d_model, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, d_model)\n","        )\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        # src: [seq_len, batch_size, d_model]\n","        src2, _ = self.self_attention(src, src, src)\n","        src = src + self.dropout(self.layer_norm1(src2))\n","        src2 = self.feedforward(src)\n","        src = src + self.dropout(self.layer_norm2(src2))\n","        return src"],"metadata":{"id":"LtO4Qr5BiebH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, d_model, num_layers, num_heads, ff_dim, dropout):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, dropout)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)])\n","\n","    def forward(self, src):\n","        src = torch.tensor(src).float()\n","        src = self.embedding(src)\n","        src = self.positional_encoding(src)\n","\n","        for layer in self.layers:\n","            src = layer(src)\n","\n","        return src"],"metadata":{"id":"HACHfdP9q8hk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the transformer-based decoder"],"metadata":{"id":"pR4o7ADbg5D2"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, ff_dim, dropout):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.encoder_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(d_model, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, d_model)\n","        )\n","        self.layer_norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, memory):\n","        tgt2, _ = self.self_attention(tgt, tgt, tgt)\n","        tgt = tgt + self.dropout(self.layer_norm1(tgt2))\n","\n","        tgt2, _ = self.encoder_attention(tgt, memory, memory)\n","        tgt = tgt + self.dropout(self.layer_norm2(tgt2))\n","\n","        tgt2 = self.feedforward(tgt)\n","        tgt = tgt + self.dropout(self.layer_norm3(tgt2))\n","\n","        return tgt"],"metadata":{"id":"YAl3Lo0lT4sC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, d_model, num_layers, num_heads, ff_dim, dropout):\n","        super(Decoder, self).__init__()\n","\n","        self.embedding = nn.Linear(output_dim, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, dropout)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, output_dim)\n","\n","    def forward(self, tgt, memory):\n","        tgt = torch.tensor(tgt).float()\n","        tgt = self.embedding(tgt)\n","        tgt = self.positional_encoding(tgt)\n","\n","        for layer in self.layers:\n","            tgt = layer(tgt, memory)\n","\n","        return self.fc_out(tgt)"],"metadata":{"id":"Ri3eB-a1q-38"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the training function"],"metadata":{"id":"PkMSsOMbg8Gd"}},{"cell_type":"code","source":["def train_model(encoder, decoder, criterion, optimizer, train_loader, num_epochs):\n","    encoder.train()\n","    decoder.train()\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","\n","        for src, tgt in train_loader:\n","            src = src.float().to(device)\n","            tgt = tgt.float().to(device)\n","\n","            optimizer.zero_grad()\n","            memory = encoder(src)\n","            output = decoder(tgt, memory)\n","\n","            loss = criterion(output.view(-1, output.size(-1)), tgt.view(-1, tgt.size(-1)))\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Reshape output and target tensors to have the same number of elements\n","            output = output.view(-1, output.size(-1))  # Flatten output\n","            tgt = tgt.view(-1, tgt.size(-1))            # Flatten target\n","\n","            # Ensure that the output and target tensors have the same number of elements\n","            if output.size(0) != tgt.size(0):\n","                min_size = min(output.size(0), tgt.size(0))\n","                output = output[:min_size]\n","                tgt = tgt[:min_size]\n","\n","            loss = criterion(output, tgt)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        epoch_loss = total_loss / len(train_loader)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","    torch.save(encoder.state_dict(), 'encoder_model.pth')\n","    torch.save(decoder.state_dict(), 'decoder_model.pth')"],"metadata":{"id":"ZmGRFxT0T--w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"djBORbM6kIwQ"}},{"cell_type":"code","source":["#input_dim = sketches\n","input_dim = 2\n","output_dim = 2\n","\n","encoder = Encoder(input_dim, d_model, num_layers, num_heads, ff_dim, dropout)\n","decoder = Decoder(output_dim, d_model, num_layers, num_heads, ff_dim, dropout)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n","\n","train_model(encoder, decoder, criterion, optimizer, trainloader, num_epochs)"],"metadata":{"id":"Q0_GuyKPkHpy","colab":{"base_uri":"https://localhost:8080/","height":775},"executionInfo":{"status":"error","timestamp":1712625057965,"user_tz":420,"elapsed":28434,"user":{"displayName":"Aditya Ashvin","userId":"05257660200781046204"}},"outputId":"4f10dc53-c194-4af7-f0d2-d9480444bd99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["()\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-56-3fcab87428f8>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  src = [torch.tensor(doodle[:-1]) for doodle in batch]\n","<ipython-input-56-3fcab87428f8>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tgt = [torch.tensor(doodle[-1]) for doodle in batch]\n"]},{"output_type":"stream","name":"stdout","text":["1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n","1350 cnt\n","()\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-c886f566e620>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-91-bbdd0e94aa82>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(encoder, decoder, criterion, optimizer, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#added float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-56-3fcab87428f8>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoodle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoodle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoodle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoodle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-56-3fcab87428f8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoodle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoodle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoodle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoodle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Set the models to eval, and run tests"],"metadata":{"id":"vLW2SPCPhEAm"}},{"cell_type":"code","source":["encoder = torch.load('encoder_model.pth')\n","decoder = torch.load('decoder_model.pth')\n","\n","encoder.eval()\n","decoder.eval()\n","\n","with torch.no_grad():\n","    for i in np.random.randint(0, len(test_sketches), size=10):\n","        input_seq = test_sketches[i]\n","\n","        encoded_seq = encoder(input_seq)\n","        output_seq = decoder(encoded_seq)\n","\n","        print(f\"Image {i+1} - Input Strokes:\")\n","        draw_strokes_real_time(input_seq)\n","        print(f\"Image {i+1} - Output Strokes:\")\n","        draw_strokes_real_time(output_seq)"],"metadata":{"id":"Sf_L6BHZWuxl"},"execution_count":null,"outputs":[]}]}