{"cells":[{"cell_type":"markdown","metadata":{"id":"TuqHOKSke9Yf"},"source":["# Installing and importing packages\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172022,"status":"ok","timestamp":1713332755915,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"},"user_tz":420},"id":"q1_oGHhBgUPF","outputId":"709c9dde-003c-4116-cefa-ce88f63d1d46"},"outputs":[],"source":["!pip install -qU svgwrite ndjson torch"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-9qaG5kqf3Le"},"outputs":[],"source":["import requests\n","import ndjson\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import time\n","import svgwrite\n","from IPython.display import SVG, display, clear_output\n","import math\n","from tqdm import trange"]},{"cell_type":"markdown","metadata":{"id":"GKpou1MkfGwm"},"source":["# Setting pre-train parameters and user-controlled knobs"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7mfLw_2MX20e"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","dataset_url = 'https://storage.googleapis.com/quickdraw_dataset/full/simplified/triangle.ndjson'\n","max_doodle_len = 5\n","max_stroke_len = 1\n","max_gen_len = 1\n","\n","batch_size = 50\n","lr = 0.001\n","num_epochs = 5\n","d_model = 512\n","num_layers = 6\n","num_heads = 8\n","ff_dim = 2048\n","dropout = 0"]},{"cell_type":"markdown","metadata":{"id":"looAqmJWeyQQ"},"source":["# Util functions for data pre-processing"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"u0L-PH36fYF4"},"outputs":[],"source":["def load_data():\n","    response = requests.get(dataset_url)\n","    data = ndjson.loads(response.text)\n","    return data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3dxOxfhTfyR4"},"outputs":[],"source":["def extract_useful_doodles(data):\n","    useful_doodles = []\n","    for doodle in data:\n","        if doodle['recognized']:\n","            useful_doodles.append(doodle['drawing'])\n","    return useful_doodles"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KmHB50hlgN_2"},"outputs":[],"source":["def zip_strokes(data):\n","    new_data = []\n","    for doodle in data:\n","        new_data.append([[list(x) for x in zip(stroke[0], stroke[1])] for stroke in doodle])\n","    return new_data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"I0yY3ZN9g3U9"},"outputs":[],"source":["def pad_all_doodles(data):\n","    global max_stroke_len\n","    for doodle in data:\n","        max_stroke_len = max(\n","            max_stroke_len,\n","            max([len(stroke) for stroke in doodle])\n","        )\n","\n","    new_data = []\n","    for doodle in data:\n","        new_doodle = []\n","        for stroke in doodle:\n","            new_stroke = np.pad(\n","                stroke,\n","                ((max_stroke_len - len(stroke), 0), (0, 0)),\n","                mode='constant',\n","                constant_values=0\n","            )\n","            new_doodle.append(new_stroke)\n","        new_data.append(np.array(new_doodle))\n","\n","    for index, doodle in enumerate(new_data):\n","        if max_doodle_len <= doodle.shape[0]:\n","            new_data[index] = doodle[doodle.shape[0] - max_doodle_len:]\n","        else:\n","            new_data[index] = np.pad(\n","                doodle,\n","                ((max_doodle_len - doodle.shape[0], 0), (max_stroke_len - doodle.shape[1], 0), (2 - doodle.shape[2], 0))\n","            )\n","\n","    new_data = np.array(new_data)\n","    new_data = new_data.reshape(new_data.shape[0], new_data.shape[1], -1)\n","\n","    return new_data"]},{"cell_type":"markdown","metadata":{"id":"b-0jLEL1e2yX"},"source":["# Util functions for visualizations"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"n8wJSbo0gajk"},"outputs":[],"source":["def draw_strokes_real_time(strokes):\n","    strokes = np.flip(strokes, axis=1)\n","\n","    dwg = svgwrite.Drawing(size=(255, 255))\n","    dwg.add(dwg.rect(insert=(0, 0), size=('100%', '100%'), fill='white'))\n","    display(SVG(dwg.tostring()))\n","\n","    idx = 2\n","    for stroke in strokes:\n","        polyline = dwg.polyline([(int(stroke[idx-2]), int(stroke[idx-1]))], stroke=\"black\", fill=\"none\", stroke_width=2)\n","\n","        dwg.add(polyline)\n","\n","        points = [(int(stroke[i*idx]), int(stroke[i*idx+1])) for i in range(1, len(stroke)//2)]\n","        for point in points:\n","            if point == (0, 0): continue\n","            #print(point)\n","            polyline.points.append(point)\n","            display(SVG(dwg.tostring()))\n","            time.sleep(0.03)\n","            clear_output(wait=True)"]},{"cell_type":"markdown","metadata":{"id":"sFMnegGpgm3l"},"source":["# Import, process and test our dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SMJs3n-ff8Ll"},"outputs":[],"source":["dataset = load_data()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"_roLWdUHbYcB"},"outputs":[],"source":["doodles = extract_useful_doodles(dataset)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"gs-kd5Qfkp3D"},"outputs":[],"source":["doodles = zip_strokes(doodles)\n","\n","# Sanity check\n","assert np.allclose(\n","    np.array([list(x) for x in zip(dataset[0]['drawing'][0][0], dataset[0]['drawing'][0][1])]),\n","    doodles[0][0]\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_wnQlPr6ktto"},"outputs":[],"source":["doodles = pad_all_doodles(doodles)\n","\n","# Sanity check\n","assert type(doodles[0]) == type(np.array([[]]))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1713332826335,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"},"user_tz":420},"id":"DAb-rJsjuFar","outputId":"bcb829f9-db3e-4990-b419-c5e6237be2b5"},"outputs":[{"data":{"text/plain":["(120500, 5, 212)"]},"metadata":{},"output_type":"display_data"}],"source":["display(doodles.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"elapsed":10508,"status":"ok","timestamp":1713332836830,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"},"user_tz":420},"id":"s7_Hh9LGglG0","outputId":"ec24d800-449a-477c-adb2-594d4c997140"},"outputs":[{"data":{"image/svg+xml":["<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" baseProfile=\"full\" height=\"255\" version=\"1.1\" width=\"255\"><defs/><rect fill=\"white\" height=\"100%\" width=\"100%\" x=\"0\" y=\"0\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"0,0\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"136,255 134,72 137,19 142,0 115,38 93,59 0,113\" stroke=\"black\" stroke-width=\"2\"/><polyline fill=\"none\" points=\"105,218 84,188 6,116\" stroke=\"black\" stroke-width=\"2\"/></svg>"],"text/plain":["<IPython.core.display.SVG object>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in np.random.randint(0, len(doodles), size=10):\n","    draw_strokes_real_time(doodles[i])\n","    time.sleep(0.5)"]},{"cell_type":"markdown","metadata":{"id":"iRQLbxXRnsgL"},"source":["# Train test val split"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"SgHgzfUBSKJS"},"outputs":[],"source":["class DoodleDataset(Dataset):\n","    def __init__(self, doodles):\n","        self.doodles = doodles\n","\n","    def __len__(self):\n","        return len(self.doodles)\n","\n","    def __getitem__(self, idx):\n","        # Get a single doodle from the array\n","        doodle = self.doodles[idx]\n","        return doodle"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"VjHuQxyPxw3W"},"outputs":[],"source":["def collate_fn(batch):\n","    src = [torch.tensor(doodle[:-1]) for doodle in batch]\n","    tgt = [torch.tensor(doodle[-1]) for doodle in batch]\n","\n","    return torch.stack(src), torch.stack(tgt)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5087,"status":"ok","timestamp":1713332841915,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"},"user_tz":420},"id":"TVRGdNxynvwA","outputId":"c9296b47-1644-4b42-e0a9-f6ce6d530225"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data: 12050\n","test data: 108450\n"]}],"source":["doodles = torch.tensor(doodles)\n","train_data, test_data = train_test_split(doodles, test_size=0.9, random_state=42)\n","\n","print(\"train data:\", len(train_data))\n","print(\"test data:\", len(test_data))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"-KaY-yeATLXS"},"outputs":[],"source":["trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"markdown","metadata":{"id":"ERVdcL0ygznu"},"source":["# Define the transformer-based encoder"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"m3ngECtTq5RQ"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = self.pe[-x.shape[-2]:] + x\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"LtO4Qr5BiebH"},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, ff_dim, dropout):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(d_model, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, d_model)\n","        )\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        # src: [seq_len, batch_size, d_model]\n","        src2, _ = self.self_attention(src, src, src)\n","        src = src + self.dropout(self.layer_norm1(src2))\n","        src2 = self.feedforward(src)\n","        src = src + self.dropout(self.layer_norm2(src2))\n","        return src"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"HACHfdP9q8hk"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, d_model, num_layers, num_heads, ff_dim, dropout):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, dropout, input_dim)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)])\n","\n","    def forward(self, src):\n","        src = torch.tensor(src).float()\n","        src = self.embedding(src)\n","        src = self.positional_encoding(src)\n","\n","        for layer in self.layers:\n","            src = layer(src)\n","\n","        return src"]},{"cell_type":"markdown","metadata":{"id":"pR4o7ADbg5D2"},"source":["# Define the transformer-based decoder"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"YAl3Lo0lT4sC"},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, ff_dim, dropout):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm1 = nn.LayerNorm(d_model)\n","        self.encoder_attention = nn.MultiheadAttention(d_model, num_heads, dropout=dropout)\n","        self.layer_norm2 = nn.LayerNorm(d_model)\n","        self.feedforward = nn.Sequential(\n","            nn.Linear(d_model, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, d_model)\n","        )\n","        self.layer_norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tgt, memory):\n","        tgt2, _ = self.self_attention(tgt, tgt, tgt)\n","        tgt = tgt + self.dropout(self.layer_norm1(tgt2))\n","\n","        tgt2 = self.feedforward(tgt)\n","        tgt = tgt + self.dropout(self.layer_norm3(tgt2))\n","\n","        return tgt"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Ri3eB-a1q-38"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, d_model, num_layers, num_heads, ff_dim, dropout):\n","        super(Decoder, self).__init__()\n","\n","        self.embedding = nn.Linear(output_dim, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, dropout, output_dim)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, ff_dim, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, output_dim)\n","\n","    def forward(self, tgt, memory):\n","        tgt = torch.tensor(tgt).float()\n","        tgt = self.embedding(tgt)\n","        tgt = self.positional_encoding(tgt)\n","\n","        for layer in self.layers:\n","            tgt = layer(tgt, memory)\n","\n","        return self.fc_out(tgt)"]},{"cell_type":"markdown","metadata":{"id":"PkMSsOMbg8Gd"},"source":["# Define the training function"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ZmGRFxT0T--w"},"outputs":[],"source":["def train_model(encoder, decoder, criterion, optimizer, train_loader, num_epochs):\n","    encoder.train()\n","    decoder.train()\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","        data_loader_iter = iter(train_loader)\n","        total_batches = len(train_loader)\n","\n","        for _ in trange(total_batches):\n","            src, tgt = next(data_loader_iter)\n","            src = src.float().to(device)\n","            tgt = tgt.float().to(device)\n","\n","            optimizer.zero_grad()\n","            memory = encoder(src)\n","            output = decoder(tgt, memory)\n","\n","            # Reshape output and target tensors to have the same number of elements\n","            output = output[:50]\n","            output = output.view(-1, output.size(-1))  # Flatten output\n","            tgt = tgt.view(-1, tgt.size(-1))           # Flatten target\n","\n","            loss = criterion(output, tgt)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        epoch_loss = total_loss / len(train_loader)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","    torch.save(encoder.state_dict(), 'encoder_model.pth')\n","    torch.save(decoder.state_dict(), 'decoder_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"djBORbM6kIwQ"},"source":["# Train the model"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3990394,"status":"ok","timestamp":1713336832296,"user":{"displayName":"Ishaan Singh","userId":"14388252339264767661"},"user_tz":420},"id":"Q0_GuyKPkHpy","outputId":"f7755130-3ca5-4b8f-9ca9-20fe15778bd0"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [01:38<00:00,  2.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Loss: 138.4563\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [01:34<00:00,  2.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Loss: 5.9198\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [01:31<00:00,  2.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Loss: 3.0640\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [01:32<00:00,  2.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Loss: 3.6418\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 241/241 [01:32<00:00,  2.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Loss: 5.1483\n"]}],"source":["input_dim = doodles.shape[-1]\n","output_dim = doodles.shape[-1]\n","\n","encoder = Encoder(input_dim, d_model, num_layers, num_heads, ff_dim, dropout)\n","decoder = Decoder(output_dim, d_model, num_layers, num_heads, ff_dim, dropout)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n","\n","import warnings\n","\n","with warnings.catch_warnings():\n","    warnings.filterwarnings(\"ignore\")\n","    train_model(encoder, decoder, criterion, optimizer, trainloader, num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"vLW2SPCPhEAm"},"source":["# Set the models to eval, and run tests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sf_L6BHZWuxl"},"outputs":[],"source":["# encoder = torch.load('encoder_model.pth')\n","# decoder = torch.load('decoder_model.pth')\n","\n","# encoder.eval()\n","# decoder.eval()\n","\n","# with torch.no_grad():\n","#     for i in np.random.randint(0, len(test_sketches), size=10):\n","#         input_seq = test_sketches[i]\n","\n","#         encoded_seq = encoder(input_seq)\n","#         output_seq = decoder(encoded_seq)\n","\n","#         print(f\"Image {i+1} - Input Strokes:\")\n","#         draw_strokes_real_time(input_seq)\n","#         print(f\"Image {i+1} - Output Strokes:\")\n","#         draw_strokes_real_time(output_seq)"]}],"metadata":{"colab":{"collapsed_sections":["vLW2SPCPhEAm"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
